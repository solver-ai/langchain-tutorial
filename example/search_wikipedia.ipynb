{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "\n",
    "\n",
    "with open(\"../conf/service.dev.yaml\", 'r') as f:\n",
    "    configs = yaml.safe_load(f)\n",
    "os.environ['OPENAI_API_KEY'] = configs['openai']['api_key']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Prepare agent components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Build prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.agents.format_scratchpad import format_to_openai_functions\n",
    "\n",
    "\n",
    "prompt = RunnablePassthrough.assign(\n",
    "    agent_scratchpad=lambda x: format_to_openai_functions(x['intermediate_steps'])\n",
    ") | ChatPromptTemplate.from_messages([\n",
    "    ('system', \"You are helpful but sassy assistant. Please think carefully and step by step then answer with korean.\"),\n",
    "    MessagesPlaceholder(variable_name='chat_history'),\n",
    "    ('user', \"{input}\"),\n",
    "    MessagesPlaceholder(variable_name='agent_scratchpad')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Build output parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.output_parsers import OpenAIFunctionsAgentOutputParser\n",
    "\n",
    "parser = OpenAIFunctionsAgentOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Build model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1 Build tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from langchain.agents import tool\n",
    "import wikipedia\n",
    "from wikipedia.exceptions import PageError, DisambiguationError\n",
    "from langchain_core.utils.function_calling import convert_to_openai_function\n",
    "\n",
    "\n",
    "class SearchWikipediaInput(BaseModel):\n",
    "    query: str = Field(description='Query to search for in Wikipedia')\n",
    "\n",
    "@tool(args_schema=SearchWikipediaInput)\n",
    "def search_wikipedia(query: str) -> str:\n",
    "    \"\"\"Do a Wikipedia search for `query`.\"\"\"\n",
    "    titles = wikipedia.search(query)\n",
    "    summaries = []\n",
    "\n",
    "    for title in titles:\n",
    "        try:\n",
    "            page = wikipedia.page(title=title, auto_suggest=False)\n",
    "            summary = page.summary\n",
    "            summaries.append(f\"{title}: {summary}\")\n",
    "            break\n",
    "        except (PageError, DisambiguationError):\n",
    "            pass\n",
    "    \n",
    "    if not summaries:\n",
    "        return \"No good Wikipedia search result was found.\"\n",
    "    \n",
    "    return '\\n\\n'.join(summaries)\n",
    "\n",
    "functions = [convert_to_openai_function(search_wikipedia)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.2 Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(temperature=0).bind(\n",
    "    functions=functions\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Build chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | model | parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Build memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory(return_messages=True, memory_key='chat_history')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Build agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "agent = AgentExecutor(agent=chain, tools=[search_wikipedia], verbose=True, memory=memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Invoking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m안녕 지민이! 나는 도움이 되는데, 내 이름은 없어. 어떻게 도와줄까?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "agent.invoke({'input': \"안녕. 난 지민이라고 해. 네 이름은 뭐야?\"});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m물어봐! 궁금한 점이 무엇이야? 어떤 도움을 원하니?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "agent.invoke({'input': \"몇 가지 궁금한 점이 있는데\"});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m물론이야! 머신러닝과 관련된 몇 가지 키워드를 알려줄게. 이 키워드들을 기반으로 공부하면 좋을 거야:\n",
      "\n",
      "1. 지도 학습 (Supervised Learning)\n",
      "2. 비지도 학습 (Unsupervised Learning)\n",
      "3. 강화 학습 (Reinforcement Learning)\n",
      "4. 신경망 (Neural Networks)\n",
      "5. 딥러닝 (Deep Learning)\n",
      "6. 데이터 전처리 (Data Preprocessing)\n",
      "7. 특성 추출 (Feature Extraction)\n",
      "8. 모델 평가 (Model Evaluation)\n",
      "9. 군집화 (Clustering)\n",
      "10. 회귀 (Regression)\n",
      "\n",
      "이 키워드들을 참고하여 머신러닝에 대해 공부해보면 좋을 거야. 어떤 키워드에 대해 더 자세히 알고 싶어?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "agent.invoke({'input': \"머신러닝과 관련된 키워드를 몇 개 선택해줘. 그걸 기반으로 공부하고 싶거든.\"});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `search_wikipedia` with `{'query': 'Supervised Learning'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mSupervised learning: Supervised learning (SL) is a paradigm in machine learning where input objects (for example, a vector of predictor variables) and a desired output value (also known as human-labeled supervisory signal) train a model. The training data is processed, building a function that maps new data on expected output values.  An optimal scenario will allow for the algorithm to correctly determine output values for unseen instances. This requires the learning algorithm to generalize from the training data to unseen situations in a \"reasonable\" way (see inductive bias). This statistical quality of an algorithm is measured through the so-called generalization error.\n",
      "\n",
      "\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `search_wikipedia` with `{'query': 'Unsupervised Learning'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mUnsupervised learning: Unsupervised learning is a method in machine learning where, in contrast to supervised learning, algorithms learn patterns exclusively from unlabeled data.  The hope is that through mimicry, which is an important mode of learning in people, the machine is forced to build a concise representation of its world and then generate imaginative content from it.\n",
      "Other methods in the supervision spectrum are Reinforcement Learning where the machine is given only a numerical performance score as guidance, and  Weak or Semi supervision where a small portion of the data is tagged, and  Self Supervision.\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `search_wikipedia` with `{'query': 'Reinforcement Learning'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mReinforcement learning: Reinforcement learning (RL) is an interdisciplinary area of machine learning and optimal control concerned with how an intelligent agent ought to take actions in a dynamic environment in order to maximize the cumulative reward. Reinforcement learning is one of three basic machine learning paradigms, alongside supervised learning and unsupervised learning.\n",
      "Reinforcement learning differs from supervised learning in not needing labelled input/output pairs to be presented, and in not needing sub-optimal actions to be explicitly corrected. Instead the focus is on finding a balance between exploration (of uncharted territory) and exploitation (of current knowledge) with the goal of maximizing the long term reward, whose feedback might be incomplete or delayed.\n",
      "The environment is typically stated in the form of a Markov decision process (MDP), because many reinforcement learning algorithms for this context use dynamic programming techniques. The main difference between the classical dynamic programming methods and reinforcement learning algorithms is that the latter do not assume knowledge of an exact mathematical model of the Markov decision process and they target large Markov decision processes where exact methods become infeasible.\u001b[0m\u001b[32;1m\u001b[1;3m지도 학습 (Supervised Learning): 지도 학습은 머신러닝의 패러다임 중 하나로, 입력 데이터와 원하는 출력 값(사람이 레이블링한 지도 신호로도 알려짐)을 사용하여 모델을 훈련시키는 방법입니다. 훈련 데이터를 처리하여 새로운 데이터를 예상 출력 값에 매핑하는 함수를 구축합니다. 최적의 시나리오는 알고리즘이 보이지 않는 인스턴스에 대해 올바른 출력 값을 정확하게 결정할 수 있도록 하는 것입니다. 이를 위해서는 학습 알고리즘이 훈련 데이터에서 보이지 않는 상황으로 일반화할 수 있어야 합니다. 이러한 알고리즘의 통계적 품질은 일반화 오차로 측정됩니다.\n",
      "\n",
      "비지도 학습 (Unsupervised Learning): 비지도 학습은 머신러닝의 한 방법으로, 지도 학습과는 달리 레이블이 없는 데이터만을 사용하여 패턴을 학습하는 방법입니다. 이 방법은 기대되는 출력 값을 가지고 있지 않기 때문에 데이터의 내재된 구조나 패턴을 발견하려고 합니다. 비지도 학습은 데이터의 특징을 자동으로 추출하거나 데이터를 군집화하는 등의 작업에 사용될 수 있습니다.\n",
      "\n",
      "강화 학습 (Reinforcement Learning): 강화 학습은 머신러닝과 최적 제어의 교차 학문적인 영역으로, 지능적인 에이전트가 누적 보상을 최대화하기 위해 동적 환경에서 어떻게 행동을 취해야 하는지에 대해 고민하는 것입니다. 강화 학습은 지도 학습과 비지도 학습과 함께 기본적인 머신러닝 패러다임 중 하나입니다. 강화 학습은 입력/출력 쌍을 명시적으로 제공받지 않고, 부적절한 행동을 명시적으로 수정할 필요가 없다는 점에서 지도 학습과 다릅니다. 대신, 탐험(미개척 영역)과 이용(현재 지식) 사이의 균형을 찾아 장기적인 보상을 최대화하는 것에 초점을 맞추고 있습니다. 피드백이 불완전하거나 지연될 수 있는 장기적인 보상을 최대화하기 위해 탐험과 이용을 조절하는 것이 목표입니다. 강화 학습에서 환경은 일반적으로 마르코프 결정 과정(Markov decision process, MDP)의 형태로 제시됩니다. 이러한 맥락에서 많은 강화 학습 알고리즘은 동적 프로그래밍 기법을 사용합니다. 전통적인 동적 프로그래밍 방법과 강화 학습 알고리즘의 주요한 차이점은 후자가 마르코프 결정 과정의 정확한 수학적 모델을 가정하지 않으며, 정확한 방법이 불가능한 대규모 마르코프 결정 과정을 대상으로 한다는 점입니다.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "agent.invoke({'input': \"너가 알려준 키워드들 중에 상위 3가지에 대해 wikipedia 검색을 사용해서 자세히 설명해줘. 영어로 검색해봐야할거야.\"});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mYou're welcome, bro! If you have any more questions, feel free to ask. I'm here to help!\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "agent.invoke({'input': \"Thank you bro.\"});"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
