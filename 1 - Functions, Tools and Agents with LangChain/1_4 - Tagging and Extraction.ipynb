{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e8e5809",
   "metadata": {},
   "source": [
    "# Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c59257e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "\n",
    "with open(\"../conf/service.dev.yaml\", 'r') as f:\n",
    "    configs = yaml.safe_load(f)\n",
    "os.environ['OPENAI_API_KEY'] = configs['openai']['api_key']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07f36d7",
   "metadata": {},
   "source": [
    "# Tagging and Extraction Using OpenAI functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa30af2b",
   "metadata": {},
   "source": [
    "# Tagging\n",
    "- https://python.langchain.com/docs/use_cases/tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9346b6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain.utils.openai_functions import convert_pydantic_to_openai_function\n",
    "# from langchain_core.utils.function_calling import convert_to_openai_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a63fa06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tagging(BaseModel):\n",
    "    \"\"\"Tag the piece of text with particular info.\"\"\"\n",
    "    sentiment: str = Field(description=\"sentiment of text, should be `pos`, `neg`, or `neutral`\") \n",
    "    language: str = Field(description=\"language of text (should be ISO 639-1 code)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5624de8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vscode/.local/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `convert_pydantic_to_openai_function` was deprecated in LangChain 0.1.16 and will be removed in 0.2.0. Use langchain_core.utils.function_calling.convert_to_openai_function() instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'name': 'Tagging',\n",
       " 'description': 'Tag the piece of text with particular info.',\n",
       " 'parameters': {'type': 'object',\n",
       "  'properties': {'sentiment': {'description': 'sentiment of text, should be `pos`, `neg`, or `neutral`',\n",
       "    'type': 'string'},\n",
       "   'language': {'description': 'language of text (should be ISO 639-1 code)',\n",
       "    'type': 'string'}},\n",
       "  'required': ['sentiment', 'language']}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_pydantic_to_openai_function(Tagging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37a15946",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "943d809d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(temperature=0)  # deterministic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffac59bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagging_functions = [convert_pydantic_to_openai_function(Tagging)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "495318e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    ('system', \"Think carefully, and then tag the text as instructed\"),\n",
    "    ('user', \"{input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5da1102",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_functions = model.bind(\n",
    "    functions=tagging_functions,\n",
    "    function_call={'name': \"Tagging\"}  # force it\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c6a5bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagging_chain = prompt | model_with_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57979948",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\\n  \"sentiment\": \"pos\",\\n  \"language\": \"en\"\\n}', 'name': 'Tagging'}})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagging_chain.invoke({'input': \"I love langchain\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2232bbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\\n  \"sentiment\": \"neg\",\\n  \"language\": \"it\"\\n}', 'name': 'Tagging'}})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagging_chain.invoke({'input': \"non mi piace questo cibo\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f967eed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers.openai_functions import JsonOutputFunctionsParser\n",
    "\n",
    "tagging_chain = prompt | model_with_functions | JsonOutputFunctionsParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae1184be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentiment': 'neg', 'language': 'it'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagging_chain.invoke({'input': \"non mi piace questo cibo\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab6d8fc",
   "metadata": {},
   "source": [
    "# Extraction\n",
    "Extraction is similar to tagging, but used for extracting multiple pieces of information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7633fadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "class Person(BaseModel):\n",
    "    \"\"\"Information about a person.\"\"\"\n",
    "    name: str = Field(description=\"person's name\")\n",
    "    age: Optional[int] = Field(description=\"person's age\")\n",
    "\n",
    "\n",
    "class Information(BaseModel):\n",
    "    \"\"\"Information to extract.\"\"\"\n",
    "    people: List[Person] = Field(description=\"List of info about people\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87dbd111",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Information',\n",
       " 'description': 'Information to extract.',\n",
       " 'parameters': {'type': 'object',\n",
       "  'properties': {'people': {'description': 'List of info about people',\n",
       "    'type': 'array',\n",
       "    'items': {'description': 'Information about a person.',\n",
       "     'type': 'object',\n",
       "     'properties': {'name': {'description': \"person's name\", 'type': 'string'},\n",
       "      'age': {'description': \"person's age\", 'type': 'integer'}},\n",
       "     'required': ['name']}}},\n",
       "  'required': ['people']}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_pydantic_to_openai_function(Information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "546e974d",
   "metadata": {},
   "outputs": [],
   "source": [
    "extraction_functions = [convert_pydantic_to_openai_function(Information)]\n",
    "extraction_model = model.bind(\n",
    "    functions=extraction_functions,\n",
    "    function_call={'name': \"Information\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "244090cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\\n  \"people\": [\\n    {\\n      \"name\": \"Joe\",\\n      \"age\": 30\\n    }\\n  ]\\n}', 'name': 'Information'}})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extraction_model.invoke(\"Joe is 30\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "218f1e09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\\n  \"people\": [\\n    {\\n      \"name\": \"Joe\",\\n      \"age\": 30\\n    },\\n    {\\n      \"name\": \"Martha\",\\n      \"age\": 0\\n    }\\n  ]\\n}', 'name': 'Information'}})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extraction_model.invoke(\"Joe is 30, his mom is Martha\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44c4ad6",
   "metadata": {},
   "source": [
    "- Martha의 나이가 0가 아님에도 0로 **추정**하는 것을 방지하기 위해 prompt를 수정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "65149841",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    ('system', \"Extract the relevant information, if not explicitly provided do not guess. Extract partial info\"),\n",
    "    ('human', \"{input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bb03353b",
   "metadata": {},
   "outputs": [],
   "source": [
    "extraction_chain = prompt | extraction_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "78dd7b21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\\n  \"people\": [\\n    {\\n      \"name\": \"Joe\",\\n      \"age\": 30\\n    },\\n    {\\n      \"name\": \"Martha\"\\n    }\\n  ]\\n}', 'name': 'Information'}})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extraction_chain.invoke({'input': \"Joe is 30, his mom is Martha\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d53ee9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "extraction_chain = prompt | extraction_model | JsonOutputFunctionsParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "beea0f4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'people': [{'name': 'Joe', 'age': 30}, {'name': 'Martha'}]}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extraction_chain.invoke({'input': \"Joe is 30, his mom is Martha\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60342051",
   "metadata": {},
   "source": [
    "- `people` 은 그저 list로 `person`을 뽑아내기 위한 용도로 필요없는 key라서 생략할 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "476bda39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers.openai_functions import JsonKeyOutputFunctionsParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "532d845e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Joe', 'age': 30}, {'name': 'Martha'}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extraction_chain = prompt | extraction_model | JsonKeyOutputFunctionsParser(key_name='people')\n",
    "extraction_chain.invoke({'input': \"Joe is 30, his mom is Martha\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6f98b2",
   "metadata": {},
   "source": [
    "# More real example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "41306ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import WebBaseLoader\n",
    "\n",
    "loader = WebBaseLoader(\"https://lilianweng.github.io/posts/2023-06-23-agent/\")\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cf1bc33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = documents[0]\n",
    "page_content = doc.page_content[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1a83ba3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Overview(BaseModel):\n",
    "    \"\"\"Overview of a section of text.\"\"\"\n",
    "    summary: str = Field(description=\"Provide a concise summary of the content.\")\n",
    "    language: str = Field(description=\"Provide the language that the content is written.\")\n",
    "    keywords: str = Field(description=\"Provide keywords.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e43ab71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "overview_tagging_functions = [\n",
    "    convert_pydantic_to_openai_function(Overview)\n",
    "]\n",
    "tagging_model = model.bind(\n",
    "    functions=overview_tagging_functions,\n",
    "    function_call={'name': \"Overview\"}\n",
    ")\n",
    "tagging_chain = prompt | tagging_model | JsonOutputFunctionsParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6838382a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'summary': 'This article discusses the concept of building autonomous agents powered by LLM (large language model) as their core controller. It explores the key components of such agent systems, including planning, memory, and tool use. It also covers various techniques for task decomposition and self-reflection in LLM-powered agents.',\n",
       " 'language': 'English',\n",
       " 'keywords': 'LLM, autonomous agents, planning, memory, tool use, task decomposition, self-reflection'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagging_chain.invoke({'input': page_content})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bdcf43b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Paper(BaseModel):\n",
    "    \"\"\"Information about papers mentioned.\"\"\"\n",
    "    title: str\n",
    "    author: Optional[str]\n",
    "\n",
    "class Info(BaseModel):\n",
    "    \"\"\"Information to extract\"\"\"\n",
    "    papers: List[Paper]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "768dafa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Info',\n",
       " 'description': 'Information to extract',\n",
       " 'parameters': {'type': 'object',\n",
       "  'properties': {'papers': {'type': 'array',\n",
       "    'items': {'description': 'Information about papers mentioned.',\n",
       "     'type': 'object',\n",
       "     'properties': {'author': {'type': 'string'}},\n",
       "     'required': ['title']}}},\n",
       "  'required': ['papers']}}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_pydantic_to_openai_function(Info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7c67a9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_extraction_functions = [\n",
    "    convert_pydantic_to_openai_function(Info)\n",
    "]\n",
    "extraction_model = model.bind(\n",
    "    functions=paper_extraction_functions,\n",
    "    function_call={'name': \"Info\"}\n",
    ")\n",
    "extraction_chain = prompt | extraction_model | JsonKeyOutputFunctionsParser(key_name='papers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c53aad92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'author': 'Lilian Weng'}]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extraction_chain.invoke({'input': page_content})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51dc8caa",
   "metadata": {},
   "source": [
    "- 정확도가 낮다. prompt를 수정하여 좀 더 원하는 방향으로 가이드해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bf16ac9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"A article will be passed to you. Extract from it all papers that are mentioned by this article.\n",
    "\n",
    "Do not extract the name of the article itself. If no papers are mentioned that's fine - you don't need to extract any! Just return an empty list.\n",
    "\n",
    "Do not make up or guess ANY extra information. Only extract what exactly is in the text.\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    ('system', template),\n",
    "    ('human', \"{input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "11281f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "extraction_chain = prompt | extraction_model | JsonKeyOutputFunctionsParser(key_name='papers')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7679cd9d",
   "metadata": {},
   "source": [
    "- 근데 왜 `title` 이 안 나오지?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "92ca76f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'author': 'Wei et al. 2022'},\n",
       " {'author': 'Yao et al. 2023'},\n",
       " {'author': 'Liu et al. 2023'},\n",
       " {'author': 'Shinn & Labash 2023'},\n",
       " {'author': 'Laskin et al. 2023'},\n",
       " {'author': 'Duan et al. 2017'}]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extraction_chain.invoke({'input': page_content})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521b626e",
   "metadata": {},
   "source": [
    "# More text processing\n",
    "한 번에 넣기 너무 긴 text는 잘라서 넣고, 나중에 합쳐야된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "eaa54c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_overlap=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "90d2bab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = text_splitter.split_text(doc.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "73b30781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f4b4068e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(matrix):\n",
    "    flat_list = []\n",
    "    for row in matrix:\n",
    "        flat_list += row\n",
    "    return flat_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "88dd6dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.runnable import RunnableLambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f4a1e988",
   "metadata": {},
   "outputs": [],
   "source": [
    "prep = RunnableLambda(lambda x: [{'input': doc} for doc in text_splitter.split_text(x)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "73a9b72e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'input': 'hi'}]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prep.invoke(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c967b250",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prep | extraction_chain.map() | flatten "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c364f19e",
   "metadata": {},
   "source": [
    "- 기본적으로 5개가 병렬적으로 처리된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2bb80c15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'author': 'Wei et al. 2022'},\n",
       " {'author': 'Yao et al. 2023'},\n",
       " {'author': 'Liu et al. 2023'},\n",
       " {'author': 'Shinn & Labash 2023'},\n",
       " {'author': 'Shinn & Labash, 2023'},\n",
       " {'author': 'Liu et al. 2023'},\n",
       " {'author': 'Laskin et al. 2023'},\n",
       " {'author': 'Laskin et al. 2023'},\n",
       " {'author': 'Duan et al. 2017'},\n",
       " {'author': 'Miller 1956'},\n",
       " {'author': 'LSH'},\n",
       " {'author': 'ANNOY'},\n",
       " {'author': 'HNSW'},\n",
       " {'author': 'FAISS'},\n",
       " {'author': 'ScaNN'},\n",
       " {'author': 'Karpas et al. 2022'},\n",
       " {'author': 'Parisi et al. 2022'},\n",
       " {'author': 'Schick et al. 2023'},\n",
       " {'author': 'Shen et al. 2023'},\n",
       " {'author': 'API-Bank (Li et al. 2023)'},\n",
       " {'author': 'ChemCrow (Bran et al. 2023)'},\n",
       " {'author': 'Boiko et al. (2023)'},\n",
       " {'author': 'Park, et al. (2023)'},\n",
       " {'author': 'Park et al.'},\n",
       " {'author': 'John Smith'},\n",
       " {'author': 'Jane Doe'},\n",
       " {'author': 'John Doe'},\n",
       " {'author': 'Jane Smith'},\n",
       " {'author': 'John Smith'},\n",
       " {'author': 'Jane Doe'},\n",
       " {'author': 'Wei et al.'},\n",
       " {'author': 'Yao et al.'},\n",
       " {'author': 'Liu et al.'},\n",
       " {'author': 'Google Blog'},\n",
       " {'author': 'Shinn & Labash'},\n",
       " {'author': 'Laskin et al.'},\n",
       " {'author': 'Karpas et al.'},\n",
       " {'author': 'Li et al.'},\n",
       " {'author': 'Shen et al.'},\n",
       " {'author': 'Bran et al.'},\n",
       " {'author': 'Boiko et al.'},\n",
       " {'author': 'Joon Sung Park, et al.'},\n",
       " {'author': 'AutoGPT'},\n",
       " {'author': 'GPT-Engineer'}]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(doc.page_content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
